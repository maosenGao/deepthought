{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This notebook about 40 MB of embedded output data, which should be put under version control.   \n",
    "Please make sure to clear all cell output using the Cell>All Output>Clear command from the menu befor committing changes!  \n",
    "Use Cell>Run all to reproduce the output.\n",
    "\n",
    "注意:这个笔记本大约有40mb的嵌入式输出数据，应该放在版本控制下。\n",
    "\n",
    "在提交更改之前，请确保使用菜单中的单元格> all output > clear命令清除所有单元格输出使用单元>全部运行以重现输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前期准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys \n",
    "# sys.path.append(r'your_path')\n",
    "# sys.path.append(r'e:\\360movedata\\users\\zx305\\documents\\github')\n",
    "# sys.path.append(r'c:\\users\\zx305\\appdata\\roaming\\python\\python36\\site-packages')\n",
    "# print(sys.path)\n",
    "\n",
    "# # 这个很有用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install msgpack --user\n",
    "#!python -m pip install --upgrade pip\n",
    "#!python3 -m pip install --upgrade pip\n",
    "#!python3 -m numpy install --upgrade numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install core -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "#!pip install mir_eval --user\n",
    "#!pip install pylearn2 --user\n",
    "# !pip install deepthought --user #这段不是这么安装的！但还没有解决\n",
    "#!pip uninstall deepthought \n",
    "# !pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #!cd/d E:\\360MoveData\\Users\\zx305\\Documents\\GitHub\\pylearn2\n",
    "# !python setup.py install \n",
    "# #!pip show pip version 10.0.1\n",
    "# #!python3 -m pip install --upgrade pip\n",
    "# #!pip show pip\n",
    "# !pip uninstall pip version  10.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 程序正式开始段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting mir_eval\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0a/fe/be4f7a59ed71938e21e89f23afe93eea0d39eb3e77f83754a12028cf1a68/mir_eval-0.6.tar.gz (87 kB)\n",
      "Requirement already satisfied: numpy>=1.7.0 in d:\\anacon\\envs\\python27\\lib\\site-packages (from mir_eval) (1.16.6)\n",
      "Requirement already satisfied: scipy>=1.0.0 in d:\\anacon\\envs\\python27\\lib\\site-packages (from mir_eval) (1.2.3)\n",
      "Collecting future\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829 kB)\n",
      "Requirement already satisfied: six in c:\\users\\zx305\\appdata\\roaming\\python\\python27\\site-packages (from mir_eval) (1.14.0)\n",
      "Building wheels for collected packages: mir-eval, future\n",
      "  Building wheel for mir-eval (setup.py): started\n",
      "  Building wheel for mir-eval (setup.py): finished with status 'done'\n",
      "  Created wheel for mir-eval: filename=mir_eval-0.6-py2-none-any.whl size=96538 sha256=6dd4081f5d5d3039accda4bf16c71be7c65dea8ac83712aecb5e4e312e5bf94d\n",
      "  Stored in directory: c:\\users\\zx305\\appdata\\local\\pip\\cache\\wheels\\0e\\ea\\c3\\d1ea149ba9dd605d1f5c1b18f3a75f8f62239a2fff5356f10a\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py2-none-any.whl size=502601 sha256=4ebaf7b8fbd099ee728f222e96e02e378bd45c9a6de740dbe70215c2d879f3b5\n",
      "  Stored in directory: c:\\users\\zx305\\appdata\\local\\pip\\cache\\wheels\\bc\\98\\13\\73310a2242c18cfb692a891879e4bd1ff4b579909ffbd92d9d\n",
      "Successfully built mir-eval future\n",
      "Installing collected packages: future, mir-eval\n",
      "Successfully installed future-0.18.2 mir-eval-0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\n"
     ]
    }
   ],
   "source": [
    "# import sys \n",
    "# sys.path.append(r'your_path')\n",
    "# sys.path.append(r'd:\\python\\anaconda3\\lib\\site-packages')\n",
    "# print(sys.path)\n",
    "\n",
    "# # 这个很有用\n",
    "!pip install mir_eval -i https://pypi.tuna.tsinghua.edu.cn/simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import librosa #音频处理用的 \n",
    "import mir_eval\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named deepthought.datasets.openmiir.metadata",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a6a567874ed0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeepthought\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepthought\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepthought\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopenmiir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_stimuli_metadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_beat_times\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mSTIMULI_VERSION\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m   \u001b[1;31m# change to 1 for older stimuli version\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named deepthought.datasets.openmiir.metadata"
     ]
    }
   ],
   "source": [
    "import IPython.display\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "import deepthought\n",
    "\n",
    "from deepthought.deepthought.datasets.openmiir.metadata import load_stimuli_metadata, save_beat_times\n",
    "\n",
    "STIMULI_VERSION = 2   # change to 1 for older stimuli version\n",
    "data_root = os.path.join(deepthought.DATA_PATH, 'OpenMIIR')\n",
    "default_save_beat_times = False # change to True to save beat time to txt file\n",
    "\n",
    "# ImportError: No module named deepthought.datasets.openmiir.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_beats(y, sr, beats):\n",
    "    \n",
    "    if y is None:\n",
    "        # Sonify the beats only\n",
    "        y_beat = mir_eval.sonify.clicks(beats, sr, length=len(y))\n",
    "    else:\n",
    "        # Sonify the beats and add them to y\n",
    "        y_beat = y + mir_eval.sonify.clicks(beats, sr, length=len(y))    \n",
    "    \n",
    "    return IPython.display.Audio(data=y_beat, rate=sr)\n",
    "\n",
    "def visualize(y, sr, title=None, playback=True, beats=None):\n",
    "    \n",
    "    # show playback widget above figure\n",
    "    if playback:\n",
    "        if title is not None:\n",
    "            print title\n",
    "        \n",
    "        if beats is None:\n",
    "            display(IPython.display.Audio(data=y, rate=sr))\n",
    "        else:\n",
    "            beat_times = librosa.frames_to_time(beats, sr=sr, hop_length=64)\n",
    "            display(play_beats(y, sr, beat_times))\n",
    "    \n",
    "    # Let's make and display a mel-scaled power (energy-squared) spectrogram\n",
    "    # We use a small hop length of 64 here so that the frames line up with the beat tracker example below.\n",
    "    S = librosa.feature.melspectrogram(y, sr=sr, n_fft=2048, hop_length=64, n_mels=128)\n",
    "\n",
    "    # Convert to log scale (dB). We'll use the peak power as reference.\n",
    "    log_S = librosa.logamplitude(S, ref_power=np.max)\n",
    "\n",
    "    # Make a new figure\n",
    "    plt.figure(figsize=(12,4))\n",
    "\n",
    "    # Display the spectrogram on a mel scale\n",
    "    # sample rate and hop length parameters are used to render the time axis\n",
    "    librosa.display.specshow(log_S, sr=sr, hop_length=64, x_axis='time', y_axis='mel')\n",
    "\n",
    "    # Put a descriptive title on the plot\n",
    "    if title is not None:\n",
    "        plt.title('mel power spectrogram ({})'.format(title))\n",
    "\n",
    "    if beats is not None:\n",
    "        # Let's draw lines with a drop shadow on the beat events\n",
    "        plt.vlines(beats, 0, log_S.shape[0], colors='k', linestyles='-', linewidth=2.5)\n",
    "        plt.vlines(beats, 0, log_S.shape[0], colors='w', linestyles='-', linewidth=1.5)\n",
    "        \n",
    "    # draw a color bar\n",
    "    plt.colorbar(format='%+02.0f dB')\n",
    "\n",
    "    # Make the figure layout compact\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # This make sure the figures are plotted in place and not after text and audio\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "def _analyze_beats(audio_filepath, bpm, label=None, tightness=400, offset=0, duration=None, vy=True, vh=True, vp=True, vb=True):\n",
    "    print audio_filepath\n",
    "    # load audio file\n",
    "#     sr = 22050  # default\n",
    "    sr = 44100  # slower but gives better results for Harry Potter Theme\n",
    "    y, sr = librosa.load(audio_filepath, sr=sr, offset=offset, duration=duration)\n",
    "    \n",
    "    if label is not None:\n",
    "        print label\n",
    "    \n",
    "    if vy:\n",
    "        visualize(y, sr, 'original')\n",
    "    \n",
    "    # split into harmonic and percussive component\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    \n",
    "    if vh:\n",
    "        visualize(y_harmonic, sr, 'harmonic component')\n",
    "    if vp:\n",
    "        visualize(y_percussive, sr, 'percussive component')\n",
    "    \n",
    "    # Now, let's run the beat tracker\n",
    "    # We'll use the percussive component for this part\n",
    "    # By default, the beat tracker will trim away any leading or trailing beats that don't appear strong enough.\n",
    "    # To disable this behavior, call beat_track() with trim=False.\n",
    "\n",
    "    tempo, beats = librosa.beat.beat_track(y=y_percussive, sr=sr, hop_length=64, trim=False, start_bpm=bpm, tightness=tightness)\n",
    "\n",
    "    # Let's re-draw the spectrogram, but this time, overlay the detected beats\n",
    "    if vb:\n",
    "        visualize(y, sr, 'with beats', beats=beats)\n",
    "\n",
    "    print 'Offset:                 %.4f s' % offset\n",
    "        \n",
    "    print 'Expected tempo:         %.2f BPM' % bpm\n",
    "    print 'Estimated tempo:        %.2f BPM' % tempo\n",
    "    print 'First 5 beat frames:   ', beats[:5]\n",
    "\n",
    "    # Frame numbers are great and all, but when do those beats occur?\n",
    "    print 'First 5 beat times:    ', librosa.frames_to_time(beats[:5], sr=sr, hop_length=64)\n",
    "    \n",
    "    return tempo, beats, librosa.frames_to_time(beats, sr=sr, hop_length=64)\n",
    "\n",
    "def get_audio_filepath(meta):\n",
    "    return os.path.join(data_root, 'audio', 'full.v{}'.format(STIMULI_VERSION), meta['audio_file'])\n",
    "\n",
    "def analyze_beats(meta, tightness=400, save=default_save_beat_times, **kwargs):\n",
    "    tempo, beat_frames, beat_times = _analyze_beats(\n",
    "        audio_filepath=get_audio_filepath(meta),\n",
    "        label=meta['label'], \n",
    "        bpm=meta['bpm'], \n",
    "        tightness=tightness, \n",
    "        offset=meta['length_of_cue'],\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    if save:\n",
    "        offset = meta['length_of_cue']\n",
    "        save_beat_times(beat_times, stimulus_id=meta['id'], offset=offset, version=STIMULI_VERSION)\n",
    "\n",
    "    return tempo, beat_frames, beat_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this is experimental\n",
    "def analyze_onsets(meta):\n",
    "    audio_filepath=os.path.join(data_root, 'audio', 'full.v{}'.format(STIMULI_VERSION), meta['audio_file'])\n",
    "    sr = 44100  # slower but gives better results for Harry Potter Theme\n",
    "    offset=meta['length_of_cue']\n",
    "    duration=None\n",
    "    print sr\n",
    "    y, sr = librosa.load(audio_filepath, sr=sr, offset=offset, duration=duration)\n",
    "    \"\"\"\n",
    "    # Get onset times from a signal\n",
    "    onset_frames = librosa.onset.onset_detect(y=y, sr=sr, hop_length=64)\n",
    "    onset_times = librosa.frames_to_time(onset_frames, sr, hop_length=64)\n",
    "\n",
    "    # Or use a pre-computed onset envelope\n",
    "    o_env = librosa.onset.onset_strength(y, sr=sr)\n",
    "    onset_frames = librosa.onset.onset_detect(onset_envelope=o_env, sr=sr)\n",
    "    onset_times = librosa.frames_to_time(onset_frames, sr, hop_length=64)\n",
    "    \"\"\"\n",
    "    onset_frames = librosa.onset.onset_detect(y=y, sr=sr, hop_length=64)\n",
    "    print onset_frames\n",
    "    visualize(y, sr, 'with beats', beats=onset_frames)\n",
    "    \n",
    "    o_env = librosa.onset.onset_strength(y, sr=sr)\n",
    "    plt.plot(o_env)\n",
    "    onset_frames = librosa.onset.onset_detect(onset_envelope=o_env, sr=sr)\n",
    "    print onset_frames\n",
    "    visualize(y, sr, 'with beats', beats=onset_frames*7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = load_stimuli_metadata(data_root, version=STIMULI_VERSION)\n",
    "# print meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to analyze onsets for stimulus 22\n",
    "analyze_onsets(meta[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to analyze onsets for stimulus 1, specify tightness\n",
    "tempo, beat_frames, beat_times = analyze_beats(meta[1], tightness=800)\n",
    "print beat_times\n",
    "print beat_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze beginning of stimulus 22, \n",
    "# suppress visualization of original signal (vy) and harmonic (vh) and percussive (vp) component\n",
    "_analyze_beats(get_audio_filepath(meta[22]), \n",
    "               bpm=166, tightness=250, offset=2.182, duration=4.0, vy=False, vh=False, vp=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test different tightness settings on stimulus 22\n",
    "_analyze_beats(get_audio_filepath(meta[22]), \n",
    "               bpm=166, tightness=250, offset=0, duration=None, vy=False, vh=False, vp=False);\n",
    "_analyze_beats(get_audio_filepath(meta[22]), \n",
    "               bpm=166, tightness=400, offset=0, duration=None, vy=False, vh=False, vp=False);\n",
    "_analyze_beats(get_audio_filepath(meta[22]), \n",
    "               bpm=166, tightness=800, offset=0, duration=None, vy=False, vh=False, vp=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyze_beats(meta[1], tightness=1000, vy=False, vh=False, vp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyze_beats(meta[2], tightness=800, vy=False, vh=False, vp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyze_beats(meta[3], tightness=800, vy=False, vh=False, vp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyze_beats(meta[4], tightness=800, vy=False, vh=False, vp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyze_beats(meta[11], tightness=800, vy=False, vh=False, vp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyze_beats(meta[12], tightness=800, vy=False, vh=False, vp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyze_beats(meta[13], tightness=800, vy=False, vh=False, vp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyze_beats(meta[14], tightness=800, vy=False, vh=False, vp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyze_beats(meta[21], tightness=800, vy=False, vh=False, vp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyze_beats(meta[22], tightness=300, vy=False, vh=False, vp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyze_beats(meta[23], tightness=800, vy=False, vh=False, vp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = analyze_beats(meta[24], tightness=800, vy=False, vh=False, vp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze cue click tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepthought.datasets.openmiir.constants import STIMULUS_IDS\n",
    "\n",
    "for stimulus_id in STIMULUS_IDS:\n",
    "    tempo, beat_frames, beat_times = _analyze_beats(\n",
    "        audio_filepath=os.path.join(data_root, 'audio', 'cues.v{}'.format(STIMULI_VERSION), meta[stimulus_id]['cue_file']), \n",
    "        label=meta[stimulus_id]['label'], \n",
    "        bpm=meta[stimulus_id]['cue_bpm'], \n",
    "        tightness=10000, vy=False, vh=False, vp=False\n",
    "    )\n",
    "    \n",
    "    if default_save_beat_times:\n",
    "        save_beat_times(beat_times, stimulus_id=stimulus_id, cue=True, version=STIMULI_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
